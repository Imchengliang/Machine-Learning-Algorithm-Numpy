{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple terms, for the given training data, Naive Bayes first learns the joint probability distribution of the input and output based on the feature conditional independence hypothesis, and then uses Bayes' theorem to calculate the maximum posterior probability based on this distribution for new instances. Naive Bayes does not directly learn the joint probability distribution of the input and output, but learns the prior probability of the class and the conditional probability of the class.\n",
    "\n",
    "$$\n",
    "P(c|x) = \\frac{P(x|c)P(c)}{P(x)} \\rightarrow \\text{Posterior Probability} = \\frac{(\\text{Likelihood})(\\text{Class Prior Probability})}{\\text{Predictor Prior Probability}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Naive\" in Naive Bayes represents the assumption of conditional independence, which means that the features used for classification are conditionally independent under the condition that the class is determined. This assumption enables the learning of Naive Bayes to be realistic. The specific steps of the Naive Bayes algorithm are as follows:\n",
    "\n",
    "Firstly, calculate the class prior probability (it can be calculated by MLE):\n",
    "$$\n",
    "p(y=c_{k})=\\frac{1}{N} \\sum ^{N}_{i=1} I(\\tilde{y}_{i}=c_{k}), \\enspace k=1,2, \\cdots, K\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then calculate the class conditional probability:\n",
    "$$\n",
    "p(x_{j}=a_{j,l} | y=c_{k}) = \\frac{\\sum ^{N}_{i=1}I(x_{i,j}=a_{j,l}, \\tilde{y}_{i}=c_{k})}{\\sum ^{N}_{i=1}I(\\tilde{y}_{i}=c_{k})} \\\\\n",
    "j=1,2, \\cdots ,n, \\enspace l=1,2, \\cdots ,s_{j}, \\enspace k=1,2, \\cdots, K\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, given a new instance, calculate the corresponding maximum posterior probability, and determine the category that it belongs:\n",
    "$$\n",
    "\\hat{y}=\\arg \\max _{c_{k}} p\\left(y=c_{k}\\right) \\prod_{j=1}^{n} p\\left(x_{j} \\mid y=c_{k}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1 x2  y\n",
       "0   1  S -1\n",
       "1   1  M -1\n",
       "2   1  M  1\n",
       "3   1  S  1\n",
       "4   1  S -1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate data sample\n",
    "X1 = [1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]\n",
    "X2 = ['S', 'M', 'M', 'S', 'S', 'S', 'M', 'M', 'L', 'L', 'L', 'M', 'M', 'L', 'L']\n",
    "y = [-1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1]\n",
    "df = pd.DataFrame({'x1':x1, 'x2':x2, 'y':y})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the feature and label\n",
    "X = df[['x1', 'x2']]\n",
    "y = df[['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training of naive bayes\n",
    "def fit(X, y):\n",
    "    classes = y[y.columns[0]].unique() \n",
    "    class_count = y[y.columns[0]].value_counts() \n",
    "    class_prior = class_count/len(y)\n",
    "\n",
    "    prior = dict()\n",
    "    for col in X.columns:\n",
    "        for j in classes:\n",
    "            p_x_y = X[(y==j).values][col].value_counts()\n",
    "            for i in p_x_y.index:\n",
    "                prior[(col, i, j)] = p_x_y[i]/class_count[j]\n",
    "\n",
    "    return classes, class_prior, prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the prediction function\n",
    "def predict(X_test): \n",
    "    res = []\n",
    "    for c in classes:\n",
    "        p_y = class_prior[c] \n",
    "        p_x_y = 1\n",
    "        for i in X_test.items():\n",
    "            p_x_y *= prior[tuple(list(i)+[c])] \n",
    "        res.append(p_y*p_x_y)\n",
    "            \n",
    "    return classes[np.argmax(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction for test data: -1\n"
     ]
    }
   ],
   "source": [
    "X_test = {'x1': 2, 'x2': 'S'}\n",
    "classes, class_prior, prior = fit(X, y)\n",
    "print('prediction for test data:', predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
