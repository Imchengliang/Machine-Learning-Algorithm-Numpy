{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRF(Conditional Random Field) is one of the classic representatives of probabilistic graphical models. The CRF model is a model that can consider adjacent timing information. For example, part-of-speech tagging is one of the most commonly used scenarios for CRF. In addition, in early deep learning semantic segmentation models, CRF was also used as a post-processing technique to optimize the segmentation results of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Undirected Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic Undirected Graphical Model is also called Markov Random Field, which uses undirected graph to represent joint probability distribution.\n",
    "\n",
    "Suppose the joint probability distribution $P(Y)$ is represented by undirected graph $G=(V,E)$, and the nodes of the graph represent random variables, and the edges represent the dependencies between random variables. If the joint probability distribution satisfies the pairwise, local or global Markov property, then the joint probability distribution is a probabilistic undirected graph model. Markov property, that is, given a set of random variables, every two random variables are conditional independent with each other.\n",
    "\n",
    "A subset of nodes in an undirected graph $G$ where any two nodes of it are connected by an edge is called a clique. If $C$ is a clique of $G$, and no node can be added to make it a larger clique, it is called the maximal clique. Based on maximal cliques, the joint probability distribution $P$ of a probabilistic undirected graph model can be written in the form of the product of functions $\\Psi_{C}\\left(Y_{C}\\right)$ over all maximal cliques $C$ in the graph:\n",
    "$$\n",
    "P(Y)=\\frac{1}{Z} \\prod_{C} \\Psi_{C}\\left(Y_{C}\\right)\n",
    "$$\n",
    "\n",
    "$Z$ is the normalization factor:\n",
    "$$\n",
    "Z=\\sum _{Y} \\prod_{C} \\Psi_{C}\\left(Y_{C}\\right)\n",
    "$$\n",
    "\n",
    "CRF is a probabilistic undirected graph model. So it satisfies some characteristics of probabilistic undirected graphs, including the above-mentioned maximum corpuscle product condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRF is the Markov random field of random variable $Y$ given the condition of random variable $X$. Suppose $X$ and $Y$ are random variables, $P(Y|X)$ is conditional probability distribution of $Y$ given the condition of $X$. $P(Y|X)$ can constitute a Markov random field represented by undirected graph $G=(V,E)$:\n",
    "$$\n",
    "P(Y_{v}|X,Y_{w},w \\neq v) = P(Y_{v}|X,Y_{w},w \\sim v)\n",
    "$$\n",
    "\n",
    "$w \\neq v$ indicates all nodes in the graph except node $v$, $w \\sim v$ represents all the nodes $w$ that are connected with node $v$ with an edge in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametric Expression of CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that $P(Y|X)$ is linear CRF, Under the condition that the random variable $X$ takes the value $x$, the conditional probability that the random variable $Y$ takes the value $y$ has the following form:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&P(y \\mid x)=\\frac{1}{Z(x)} \\exp \\left(\\sum_{i, k} \\lambda_{k} t_{k}\\left(y_{i-1}, y_{i}, x, i\\right)+\\sum_{i, l} u_{l} s_{l}\\left(y_{i}, x, i\\right)\\right) \\\\\n",
    "&Z(x)=\\sum_{y} \\exp \\left(\\sum_{i, k} \\lambda_{k} t_{k}\\left(y_{i-1}, y_{i}, x, i\\right)+\\sum_{i, l} u_{l} s_{l}\\left(y_{i}, x, i\\right)\\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the formula above, $t_{k}$ and $s_{l}$ are characteristic function, $\\lambda_{k}$ and $u_{l}$ are corresponding weight, $Z(x)$ is normalization factor, and the summation is performed over all possible output sequences.\n",
    "\n",
    "For example, in a part-of-speech tagging task, $x$ is the input of the full sentence, $i$ is the current position, $y_{i}$ and $y_{i-1}$ are the labels of current position and previous position. The above four items are used as the input of the characteristic function. $t_{k}$ is the transition characteristic function and $s_{l}$ is the state characteristic function, and they take the value 1 when the characteristic condition is satisfied, otherwise, they take the value 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three Key Problems in CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear CRF needs to solve three core problems, including forward-backward probability estimation algorithm, learning algorithm based on maximum likelihood and Newton optimization, and prediction algorithm based on Viterbi algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Forward-Backward Algorithm\n",
    "\n",
    "The probability estimation algorithm for CRF is calculating conditional probability $P(y_{i}|x)$, $P(y_{i-1},y_{i}|x)$ and corresponding estimation under the given conditional probability distribution $P(y|x)$, input sequence $x$ and out put sequence $y$.\n",
    "\n",
    "Forward-Backward algorithm can be used to calculate conditional probability $P(y_{i}|x)$ and $P(y_{i-1},y_{i}|x)$. In the forward part, $\\alpha_{i}(y_{i}|x)$ represents the denormalized probability of the partial label sequence preceding position $i$ when the label at sequence position $i$ is $y_{i}$. The following defines the denormalized probability of transition from $y_{i-1}$ to $y_{i}$ when $y_{i-1}$ is given:\n",
    "$$\n",
    "M_{i}\\left(y_{i-1}, y_{i} \\mid x\\right)=\\exp \\left(\\sum_{k=1}^{K} w_{k} f_{k}\\left(y_{i-1}, y_{i}, x, i\\right)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correspondingly, when the label at sequence position $i$+1 is $y_{i+1},$ the denormalized probability of the partial label sequence before position $i$+1 can be obtained:\n",
    "$$\n",
    "\\alpha_{i+1}\\left(y_{i+1} \\mid x\\right)=\\alpha_{I}\\left(y_{i} \\mid x\\right) M_{i+1}\\left(y_{i+1}, y_{i} \\mid x\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition at the start of the sequence:\n",
    "$$\n",
    "\\alpha_{0}\\left(y_{0} \\mid x\\right)=\\left\\{\\begin{array}{lr}\n",
    "1 & y_{0}=\\text { start } \\\\\n",
    "0 & \\text { else }\n",
    "\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that the number of possible labels is $m$, then there are $m$ different values of $y_{i}$. Using $\\alpha_{i}(x)$ to represent the forward vector composed of these $m$ values as follows:\n",
    "$$\n",
    "\\alpha_{i}(x) = (\\alpha_{i}(y_{i}=1|x), \\alpha_{i}(y_{i}=2|x), \\cdots, \\alpha_{i}(y_{i}=m|x))^{\\top}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix $M_{i}(x)$ represents a $m \\times n$ matrix that consists of $M_{i}\\left(y_{i-1}, y_{i} \\mid x\\right)$:\n",
    "$$\n",
    "M_{i}(x)=[M_{i}\\left(y_{i-1}, y_{i} \\mid x\\right)]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final recursion formula can be expressed by the matrix as:\n",
    "$$\n",
    "\\alpha^{\\top}_{i+1}(x)=\\alpha^{\\top}_{i}(x)M_{i}(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correspondingly, the backward calculation process can be defined in the similar way. Define the denormalized probability $\\beta_{i}(y_{i}|x)$ of the partial label sequence after position $i$ when the label at sequence position $i$ is $y_{i}$:\n",
    "$$\n",
    "\\beta_{i}\\left(y_{i} \\mid x\\right)=M_{i}\\left(y_{i}, y_{i+1} \\mid x\\right) \\beta_{i+1}\\left(y_{i+1} \\mid x\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition at the end of the sequence:\n",
    "$$\n",
    "\\beta_{n+1}\\left(y_{n+1} \\mid x\\right)=\\left\\{\\begin{array}{lr}\n",
    "1 & y_{n+1}=\\text { stop } \\\\\n",
    "0 & \\text { else }\n",
    "\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectorized expression of above formula is:\n",
    "$$\n",
    "\\beta_{i}\\left( x\\right)=M_{i}\\left( x\\right) \\beta_{i+1}\\left( x\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalization factor is:\n",
    "$$\n",
    "Z(x)=\\sum_{c=1}^{m} \\alpha_{n}\\left(y_{n} \\mid x\\right)=\\sum_{c=1}^{m} \\beta_{1}\\left(y_{c} \\mid x\\right)\n",
    "$$\n",
    "\n",
    "The vectorized expression of $Z(x)$ is:\n",
    "$$\n",
    "Z(x) = \\alpha^{\\top}_{n}(x) \\cdot 1 = 1^{\\top} \\cdot \\beta_{1}(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to forward-backward algorithm, the conditional probability when the label of sequence position $i$ is $y_{i}$, the conditional probability when the label of sequence position $i$-1 and $i$ is $y_{i}$ are $y_{i-1}$ and $y_{i}$:\n",
    "$$\n",
    "\\begin{gathered}\n",
    "P\\left(Y_{i}=y_{i} \\mid x\\right)=\\frac{\\alpha_{i}^{T}\\left(y_{i} \\mid x\\right) \\beta_{i}\\left(y_{i} \\mid x\\right)}{Z(x)} \\\\\n",
    "P\\left(Y_{i-1}=y_{i}, Y_{i}=y_{i} \\mid x\\right)=\\frac{\\alpha_{i-1}^{T}\\left(y_{i-1} \\mid x\\right) M_{i}\\left(y_{i-1}, y_{i} \\mid x\\right) \\beta_{i}\\left(y_{i} \\mid x\\right)}{Z(x)}\n",
    "\\end{gathered}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Learning Algorithm\n",
    "\n",
    "When the training data set $X$, the corresponding label sequence $Y$ and $K$ characteristic function $f_{k}(x,y)$ are given, CRF needs to learn the model parameter $w_{k}$ and conditional probability $P_{w}(y|x)$, $w_{k}$ and $P_{w}(y|x)$ satisfy the following condition:\n",
    "$$\n",
    "P_{w}(y \\mid x)=\\frac{1}{Z_{w}(x)} \\exp \\sum_{k=1}^{K} w_{k} f_{k}(x, y)=\\frac{\\exp \\sum_{k=1}^{K} w_{k} f_{k}(x, y)}{\\sum_{y} \\exp \\sum_{k=1}^{K} w_{k} f_{k}(x, y)}\n",
    "$$\n",
    "\n",
    "The formula above is a softmax function. When model parameter $w_{k}$ is obtained after the training, it can be put in the softmax function to calculate $P_{w}(y|x)$.\n",
    "\n",
    "The learning model of linear CRF is actually a logarithmic linear model defined on time series data, and its learning methods include maximum likelihood estimation and regularized maximum likelihood estimation. Model optimization algorithms include gradient descent, Newton, quasi-Newton, and iterative scaling methods, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Prediction Algorithm\n",
    "\n",
    "The prediction problem in CRF is to find the output sequence $y^{*}$ with the largest conditional probability when the conditional random field $P(Y|X)$ and the input sequence $x$ are given. CRF uses Viterbi algorithm to process label prediction.\n",
    "\n",
    "In Viterbi algorithm, the inputs are feature vector $F(y,x)$, weight vector $w$ and observation sequence $x=(x_{1},x_{2},\\cdots,x_{n})$, the output is the optimal path $y^{*}=(y^{*}_{1},y^{*}_{2},\\cdots,y^{*}_{n})$. The algorithm flow is shown as below:\n",
    "\n",
    "(1) Initialization:\n",
    "$$\n",
    "\\delta_{1}(i)=w \\times F_{1}(y_{0}=\\text{start}, y_{1}=k, x), \\enspace j=1,2, \\ldots, m\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Recursion: for $i=2,3,\\cdots,n$\n",
    "$$\n",
    "\\delta_{i}(l)=\\max _{1<=j<=m}\\left\\{\\delta_{i-1}(j)+w \\cdot F_{i}\\left(y_{i-1}=j, y_{i}=l, x\\right)\\right\\}, l=1,2, \\ldots, m \\\\\n",
    "\\Psi_{i}(l)=\\arg \\max _{1<=j<m}\\left\\{\\delta_{i-1}(j)+w \\cdot F_{i}\\left(y_{i-1}=j, y_{i}=l, x\\right)\\right\\}, l=1,2, \\ldots, m\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Termination: \n",
    "$$\n",
    "\\max _{y}(w \\cdot F(y, x))=\\max _{1<=j<=m} \\delta_{n}(j), y_{n}^{*}=\\arg \\max _{1<=j<=m} \\delta_{n}(j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Optimal path backtracking: for $i=n-1, n-2, \\cdots, 1$\n",
    "$$\n",
    "y^{*}_{i}= \\Psi_{i+1}(y^{*}_{i+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of Viterbi algorithm:\n",
    " \n",
    "<img src=\"1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the shortest path from $S$ to $E$, Viterbi algorithm would not compare all these paths one by one. Instead, it first compares the three paths that include $B1$ to find the shortest one among these three. And then do the same to $B2$ and $B3$. Finally, comparing the three paths found above to obtain the optimal one. From this process, it's clear that the Viterbi algorithm is a dynamic programming algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRF in sklearn\n",
    "import ssl\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2002 to\n",
      "[nltk_data]     /Users/imchengliang/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/conll2002.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "# 基于NLTK下载示例数据集\n",
    "nltk.download('conll2002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Melbourne', 'NP', 'B-LOC'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('Australia', 'NP', 'B-LOC'),\n",
       " (')', 'Fpt', 'O'),\n",
       " (',', 'Fc', 'O'),\n",
       " ('25', 'Z', 'O'),\n",
       " ('may', 'NC', 'O'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('EFE', 'NC', 'B-ORG'),\n",
       " (')', 'Fpt', 'O'),\n",
       " ('.', 'Fp', 'O')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置训练和测试样本\n",
    "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
    "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))\n",
    "\n",
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单词转化为数值特征\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': 'melbourne',\n",
       " 'word[-3:]': 'rne',\n",
       " 'word[-2:]': 'ne',\n",
       " 'word.isupper()': False,\n",
       " 'word.istitle()': True,\n",
       " 'word.isdigit()': False,\n",
       " 'postag': 'NP',\n",
       " 'postag[:2]': 'NP',\n",
       " 'BOS': True,\n",
       " '+1:word.lower()': '(',\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isupper()': False,\n",
       " '+1:postag': 'Fpa',\n",
       " '+1:postag[:2]': 'Fp'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_sents[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8323 1517\n"
     ]
    }
   ],
   "source": [
    "# 构造训练集和测试集\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7964686316443963"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建CRF模型实例\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "# 模型训练\n",
    "crf.fit(X_train, y_train)\n",
    "# 类别标签\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "# 模型预测\n",
    "y_pred = crf.predict(X_test)\n",
    "# 计算F1得分\n",
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                    average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "classification_report() takes 2 positional arguments but 3 positional arguments (and 1 keyword-only argument) were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/imchengliang/Downloads/Code/ML/Conditional Random Field/CRF.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/imchengliang/Downloads/Code/ML/Conditional%20Random%20Field/CRF.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 打印B和I组的模型结果\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/imchengliang/Downloads/Code/ML/Conditional%20Random%20Field/CRF.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sorted_label \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/imchengliang/Downloads/Code/ML/Conditional%20Random%20Field/CRF.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     labels,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/imchengliang/Downloads/Code/ML/Conditional%20Random%20Field/CRF.ipynb#X53sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m name: (name[\u001b[39m1\u001b[39m:], name[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/imchengliang/Downloads/Code/ML/Conditional%20Random%20Field/CRF.ipynb#X53sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/imchengliang/Downloads/Code/ML/Conditional%20Random%20Field/CRF.ipynb#X53sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(metrics\u001b[39m.\u001b[39;49mflat_classification_report(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/imchengliang/Downloads/Code/ML/Conditional%20Random%20Field/CRF.ipynb#X53sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     y_test, y_pred, labels\u001b[39m=\u001b[39;49msorted_label, digits\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/imchengliang/Downloads/Code/ML/Conditional%20Random%20Field/CRF.ipynb#X53sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn_crfsuite/metrics.py:13\u001b[0m, in \u001b[0;36m_flattens_y.<locals>.wrapper\u001b[0;34m(y_true, y_pred, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m y_true_flat \u001b[39m=\u001b[39m flatten(y_true)\n\u001b[1;32m     12\u001b[0m y_pred_flat \u001b[39m=\u001b[39m flatten(y_pred)\n\u001b[0;32m---> 13\u001b[0m \u001b[39mreturn\u001b[39;00m func(y_true_flat, y_pred_flat, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn_crfsuite/metrics.py:68\u001b[0m, in \u001b[0;36mflat_classification_report\u001b[0;34m(y_true, y_pred, labels, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39mReturn classification report for sequence items.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m metrics\u001b[39m.\u001b[39;49mclassification_report(y_true, y_pred, labels, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: classification_report() takes 2 positional arguments but 3 positional arguments (and 1 keyword-only argument) were given"
     ]
    }
   ],
   "source": [
    "# 打印B和I组的模型结果\n",
    "sorted_label = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_label, digits=3\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
