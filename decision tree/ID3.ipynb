{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classic decision tree algorithms include ID3 algorithm, C4.5 algorithm, and CART algorithm. The main difference among these three is that they have different feature selection criteria. ID3 selects features based on information divergence, C4.5 is based on the ratio of information divergence, and CART is based on the Gini index. \n",
    "\n",
    "As a basic classification and regression method, decision trees can be understood in the following two ways. One is that we can think of a decision tree as a set of if-then rules, and the other is the conditional probability distribution of the class given the features.\n",
    "\n",
    "According to the above two ways of understanding, we can regard the essence of decision tree as summarizing a set of classification rules from the training data set, or it can be regarded as estimating the conditional probability model according to the training data set. The learning process of the entire decision tree is a process of recursively selecting the optimal feature and dividing the data set according to the feature, so that each sample gets a best classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the introduction of information divergence, we need to understand entropy, which is one way to represent the measurement of the uncertainty of random variables. If the probability of a discrete random variable is defined as $P(X=x_{i})=p_{i}$, the the entropy of $X$ is $H(X)=-\\sum_{i=1}^{n}p_{i} \\log p_{i}$\n",
    "\n",
    "Similarly, for a continuous random variable $Y$, its entropy can be defined as: $H(Y)=-\\int_{-\\infty}^{+\\infty} f(y) \\log f(y) d y$\n",
    "\n",
    "When random variable $X$ is given, the entropy of random variable $Y$ can be defined as condition entropy: $H(Y|X) = -\\sum_{i=1}^{n}p_{i} H(Y|X=x_{i})$ \n",
    "\n",
    "Information divergence is the reduced degree of information uncertainty for class $Y$ when the information of feature $X$ is obtained in the data. Assuming that the entropy of data set $D$ is $H(D)$, the condition entropy with give feature $A$ is $H(D|A)$. Then, the information divergence of feature $A$ for the data set can be expressed as: $g(D,A)=H(D)-H(D|A)$\n",
    "\n",
    "When the information divergence is larger, the contribution of this feature to data set certainty is larger, indicating that this feature has strong classification-ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>humility</th>\n",
       "      <th>outlook</th>\n",
       "      <th>play</th>\n",
       "      <th>temp</th>\n",
       "      <th>windy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>sunny</td>\n",
       "      <td>no</td>\n",
       "      <td>hot</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>sunny</td>\n",
       "      <td>no</td>\n",
       "      <td>hot</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>overcast</td>\n",
       "      <td>yes</td>\n",
       "      <td>hot</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>rainy</td>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td>rainy</td>\n",
       "      <td>yes</td>\n",
       "      <td>cool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>normal</td>\n",
       "      <td>rainy</td>\n",
       "      <td>no</td>\n",
       "      <td>cool</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>normal</td>\n",
       "      <td>overcast</td>\n",
       "      <td>yes</td>\n",
       "      <td>cool</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>high</td>\n",
       "      <td>sunny</td>\n",
       "      <td>no</td>\n",
       "      <td>mild</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>normal</td>\n",
       "      <td>sunny</td>\n",
       "      <td>yes</td>\n",
       "      <td>cool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>normal</td>\n",
       "      <td>rainy</td>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>normal</td>\n",
       "      <td>sunny</td>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>high</td>\n",
       "      <td>overcast</td>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>normal</td>\n",
       "      <td>overcast</td>\n",
       "      <td>yes</td>\n",
       "      <td>hot</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>high</td>\n",
       "      <td>rainy</td>\n",
       "      <td>no</td>\n",
       "      <td>mild</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   humility   outlook play  temp  windy\n",
       "0      high     sunny   no   hot  False\n",
       "1      high     sunny   no   hot   True\n",
       "2      high  overcast  yes   hot  False\n",
       "3      high     rainy  yes  mild  False\n",
       "4    normal     rainy  yes  cool  False\n",
       "5    normal     rainy   no  cool   True\n",
       "6    normal  overcast  yes  cool   True\n",
       "7      high     sunny   no  mild  False\n",
       "8    normal     sunny  yes  cool  False\n",
       "9    normal     rainy  yes  mild  False\n",
       "10   normal     sunny  yes  mild   True\n",
       "11     high  overcast  yes  mild   True\n",
       "12   normal  overcast  yes   hot  False\n",
       "13     high     rainy   no  mild   True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from math import log\n",
    "\n",
    "df = pd.read_csv('example_data.csv') \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the information entropy of the target feature:\n",
    "$$E(S)= \\sum _{i=1}^{c} -p_{i} \\log _{2} p_{i}$$\n",
    "\n",
    "Example: Yes = 9 and No = 5\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text { Entropy(Yes \\& No) }&=\\text { Entropy }(9,5) \\\\\n",
    "&=\\text { Entropy }(0.64,0.36) \\\\\n",
    "&=-\\left(0.64 \\log _{2} 0.64\\right)-\\left(0.36 \\log _{2} 0.36\\right) \\\\\n",
    "&=0.94\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(ele): \n",
    "    # Calculating the probability distribution of list value \n",
    "    probs = [ele.count(i)/len(ele) for i in set(ele)]\n",
    "    # Calculating entropy value\n",
    "    entropy = -sum([prob*log(prob, 2) for prob in probs]) \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data set based on feature and feature value\n",
    "def split_dataframe(data, col): \n",
    "    '''\n",
    "    input: dataframe, column name\n",
    "    output: a dict of splited dataframe\n",
    "    '''\n",
    "    # unique value of column\n",
    "    unique_values = data[col].unique()\n",
    "    # empty dict of dataframe\n",
    "    result_dict = {elem : pd.DataFrame for elem in unique_values} \n",
    "    # split dataframe based on column value\n",
    "    for key in result_dict.keys():\n",
    "        result_dict[key] = data[:][data[col] == key] \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the best column based on infomation gain\n",
    "def choose_best_col(df, label): \n",
    "    ''' \n",
    "    input: datafram, label\n",
    "    output: max infomation divergence, best column,\n",
    "    splited dataframe dict based on best column.\n",
    "    '''\n",
    "    # Calculating label's entropy\n",
    "    entropy_D = entropy(df[label].tolist())\n",
    "    # columns list except label\n",
    "    cols = [col for col in df.columns if col not in [label]]\n",
    "    # initialize the max infomation gain, best column and best splited dict \n",
    "    max_value, best_col = -999, None\n",
    "    max_splited = None\n",
    "    # split data based on different column\n",
    "    for col in cols:\n",
    "        splited_set = split_dataframe(df, col) \n",
    "        entropy_DA = 0\n",
    "        for subset_col, subset in splited_set.items():\n",
    "            # calculating splited dataframe label's entropy\n",
    "            entropy_Di = entropy(subset[label].tolist())\n",
    "            # calculating entropy of current feature\n",
    "            entropy_DA += len(subset)/len(df) * entropy_Di\n",
    "        # calculating infomation gain of current feature\n",
    "        info_gain = entropy_D - entropy_DA \n",
    "        if info_gain > max_value:\n",
    "            max_value, best_col = info_gain, col\n",
    "            max_splited = splited_set\n",
    "    return max_value, best_col, max_splited\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2467498197744391, 'outlook', {'sunny':    humility outlook play  temp  windy\n",
       "  0      high   sunny   no   hot  False\n",
       "  1      high   sunny   no   hot   True\n",
       "  7      high   sunny   no  mild  False\n",
       "  8    normal   sunny  yes  cool  False\n",
       "  10   normal   sunny  yes  mild   True,\n",
       "  'overcast':    humility   outlook play  temp  windy\n",
       "  2      high  overcast  yes   hot  False\n",
       "  6    normal  overcast  yes  cool   True\n",
       "  11     high  overcast  yes  mild   True\n",
       "  12   normal  overcast  yes   hot  False,\n",
       "  'rainy':    humility outlook play  temp  windy\n",
       "  3      high   rainy  yes  mild  False\n",
       "  4    normal   rainy  yes  cool  False\n",
       "  5    normal   rainy   no  cool   True\n",
       "  9    normal   rainy  yes  mild  False\n",
       "  13     high   rainy   no  mild   True})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose_best_col(df, 'play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3Tree:\n",
    "    # define a Node class class Node:\n",
    "    class Node:\n",
    "        def __init__(self, name): \n",
    "            self.name = name\n",
    "            self.connections = {}\n",
    "\n",
    "        def connect(self, label, node): \n",
    "            self.connections[label] = node\n",
    "\n",
    "    def __init__(self, data, label): \n",
    "        self.columns = data.columns \n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.root = self.Node(\"Root\")\n",
    "\n",
    "    # print tree method\n",
    "    def print_tree(self, node, tabs):\n",
    "        print(node.connections)\n",
    "        print(tabs + node.name)\n",
    "        for connection, child_node in node.connections.items():\n",
    "            print(tabs + \"\\t\" + \"(\" + str(connection) + \")\")\n",
    "            self.print_tree(child_node, tabs + \"\\t\\t\") \n",
    "            \n",
    "    def construct_tree(self):\n",
    "        self.construct(self.root, \"\", self.data, self.columns)\n",
    "\n",
    "    # construct tree\n",
    "    def construct(self, parent_node, parent_connection_label, input_data, columns): \n",
    "        max_value, best_col, max_splited = choose_best_col(input_data[columns], self.label)\n",
    "        if not best_col:\n",
    "            node = self.Node(input_data[self.label].iloc[0])\n",
    "            parent_node.connect(parent_connection_label, node)\n",
    "            return\n",
    "\n",
    "        node = self.Node(best_col) \n",
    "        parent_node.connect(parent_connection_label, node)\n",
    "        new_columns = [col for col in columns if col != best_col] \n",
    "        # Recursively constructing decision trees\n",
    "        for splited_value, splited_data in max_splited.items():\n",
    "            self.construct(node, splited_value, splited_data, new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': <__main__.ID3Tree.Node object at 0x7fecf8c80210>}\n",
      "Root\n",
      "\t()\n",
      "{'sunny': <__main__.ID3Tree.Node object at 0x7fecd8864d90>, 'overcast': <__main__.ID3Tree.Node object at 0x7fecf8cc9e90>, 'rainy': <__main__.ID3Tree.Node object at 0x7fecf8cc9b50>}\n",
      "\t\toutlook\n",
      "\t\t\t(sunny)\n",
      "{'high': <__main__.ID3Tree.Node object at 0x7fecf8cc9a10>, 'normal': <__main__.ID3Tree.Node object at 0x7fecf8cc9910>}\n",
      "\t\t\t\thumility\n",
      "\t\t\t\t\t(high)\n",
      "{'hot': <__main__.ID3Tree.Node object at 0x7fecd8864d10>, 'mild': <__main__.ID3Tree.Node object at 0x7fecd8864790>}\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(hot)\n",
      "{False: <__main__.ID3Tree.Node object at 0x7fecd8864390>, True: <__main__.ID3Tree.Node object at 0x7fecd88643d0>}\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(False)\n",
      "{}\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t\t\t\t\t(True)\n",
      "{}\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t\t\t(mild)\n",
      "{False: <__main__.ID3Tree.Node object at 0x7fecd8864ed0>}\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(False)\n",
      "{}\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t(normal)\n",
      "{'cool': <__main__.ID3Tree.Node object at 0x7fecd8864350>, 'mild': <__main__.ID3Tree.Node object at 0x7fecd88642d0>}\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(cool)\n",
      "{False: <__main__.ID3Tree.Node object at 0x7fecd8864dd0>}\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(False)\n",
      "{}\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(mild)\n",
      "{True: <__main__.ID3Tree.Node object at 0x7fecd8864ad0>}\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(True)\n",
      "{}\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t(overcast)\n",
      "{'high': <__main__.ID3Tree.Node object at 0x7fecd8864cd0>, 'normal': <__main__.ID3Tree.Node object at 0x7fecd8864b10>}\n",
      "\t\t\t\thumility\n",
      "\t\t\t\t\t(high)\n",
      "{'hot': <__main__.ID3Tree.Node object at 0x7fecd8864c90>, 'mild': <__main__.ID3Tree.Node object at 0x7fecd8864190>}\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(hot)\n",
      "{False: <__main__.ID3Tree.Node object at 0x7fecd8864d50>}\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(False)\n",
      "{}\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(mild)\n",
      "{True: <__main__.ID3Tree.Node object at 0x7fecd8864290>}\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(True)\n",
      "{}\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t(normal)\n",
      "{'cool': <__main__.ID3Tree.Node object at 0x7fecc952b790>, 'hot': <__main__.ID3Tree.Node object at 0x7fecf8c7aa50>}\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(cool)\n",
      "{True: <__main__.ID3Tree.Node object at 0x7fecd8864090>}\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(True)\n",
      "{}\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(hot)\n",
      "{False: <__main__.ID3Tree.Node object at 0x7fecc8cc5990>}\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(False)\n",
      "{}\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t(rainy)\n",
      "{False: <__main__.ID3Tree.Node object at 0x7fecf8c7a510>, True: <__main__.ID3Tree.Node object at 0x7fecf8c7ae90>}\n",
      "\t\t\t\twindy\n",
      "\t\t\t\t\t(False)\n",
      "{'high': <__main__.ID3Tree.Node object at 0x7fecd8864f90>, 'normal': <__main__.ID3Tree.Node object at 0x7fecd8864250>}\n",
      "\t\t\t\t\t\thumility\n",
      "\t\t\t\t\t\t\t(high)\n",
      "{'mild': <__main__.ID3Tree.Node object at 0x7fecf8c7a090>}\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(mild)\n",
      "{}\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(normal)\n",
      "{'cool': <__main__.ID3Tree.Node object at 0x7fecd8864c10>, 'mild': <__main__.ID3Tree.Node object at 0x7fecd8858490>}\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(cool)\n",
      "{}\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t\t\t(mild)\n",
      "{}\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t(True)\n",
      "{'normal': <__main__.ID3Tree.Node object at 0x7fecd8864210>, 'high': <__main__.ID3Tree.Node object at 0x7fecd8864f50>}\n",
      "\t\t\t\t\t\thumility\n",
      "\t\t\t\t\t\t\t(normal)\n",
      "{'cool': <__main__.ID3Tree.Node object at 0x7fecd8864bd0>}\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(cool)\n",
      "{}\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t\t\t(high)\n",
      "{'mild': <__main__.ID3Tree.Node object at 0x7fecd88640d0>}\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(mild)\n",
      "{}\n",
      "\t\t\t\t\t\t\t\t\t\tno\n"
     ]
    }
   ],
   "source": [
    "tree = ID3Tree(df, 'play')\n",
    "tree.construct_tree()\n",
    "tree.print_tree(tree.root, \"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77183bd9d6786d4e91446bef4a81b437a8a214642262a83c9f17e3391316dc6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
