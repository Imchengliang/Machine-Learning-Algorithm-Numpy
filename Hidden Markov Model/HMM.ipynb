{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMM (Hidden Markov Model) is a process of randomly generating observation sequences from hidden Markov chains, which is a classic probabilistic graphical model.\n",
    "\n",
    "<img src=\"1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMM is a probability model about time series, in which the sequence of states randomly generated by the hidden Markov chain is called the state sequence, and the sequence of states generated by each state is called the observation sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMM is determined by initial state probability vector $\\pi$, state transition probability matrix $A$ and observation probability matrix $B$. Among these three, $\\pi$ and $A$ determine the state sequence, $B$ determines the observation sequence. Therefore, HMM can be represented by a ternary notation: \n",
    "$$\n",
    "\\lambda = (A, B, \\pi)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set $Q$ to be the set of $N$ possible states and $V$ to be the set of $M$ possible observations:\n",
    "$$\n",
    "Q=\\{q_{1},q_{2},\\cdots,q_{N}\\}, \\enspace V=\\{v_{1},v_{2},\\cdots,v_{M}\\}\n",
    "$$\n",
    "\n",
    "$I$ is a state sequence with length $T$ and $O$ is a observation sequence with length $T$:\n",
    "$$\n",
    "I=(i_{1},i_{2},\\cdots,i_{T}), \\enspace O=(o_{1},o_{2},\\cdots,o_{T})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdistribution(dist): \n",
    "    r = np.random.rand()\n",
    "    for ix, p in enumerate(dist):\n",
    "        if r < p: \n",
    "            return ix\n",
    "        r -= p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate observation sequence\n",
    "def generate(N, M, pi, A, B, T):\n",
    "    # generate the first state based on the initial probability\n",
    "    i = rdistribution(pi)  \n",
    "    # generate the first observation\n",
    "    o = rdistribution(B[i])  \n",
    "    observed_data = [o]\n",
    "    # iteration for generating the remaining states and observations\n",
    "    for _ in range(T-1):        \n",
    "        i = rdistribution(A[i])\n",
    "        o = rdistribution(B[i])\n",
    "        observed_data.append(o)\n",
    "    return observed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $A$ is state transition matrix that can be expressed as:\n",
    "$$\n",
    "A=[a_{ij}]_{N \\times N}\n",
    "$$\n",
    "\n",
    "$a_{ij}$ represents the probability of transition from state $q_{i}$ at time $t$ to state $q_{j}$ at time $t+1$:\n",
    "$$\n",
    "a_{ij}=P(i_{t+1}=q_{j}|i_{t}=q_{i}), \\enspace i,j=1,2,\\cdots,N\n",
    "$$\n",
    "\n",
    "$B$ is observation probability matrix that can be expressed as:\n",
    "$$\n",
    "B=[b_{j}(k)]_{N \\times N}\n",
    "$$\n",
    "\n",
    "$b_{j}(k)$ represents the probability of generating observation $v_{k}$ from state $q_{j}$ at time $t$:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&b_{j}(k)=P(o_{t}=v_{k}|i_{t}=q_{j})\\\\\n",
    "&k=1,2,\\cdots,M; \\enspace j=1,2,\\cdots,M\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial state probability vector\n",
    "pi = np.array([0.25, 0.25, 0.25, 0.25])\n",
    "# state transition probability matrix\n",
    "A = np.array([\n",
    "    [0,  1,  0, 0],\n",
    "    [0.4, 0, 0.6, 0],\n",
    "    [0, 0.4, 0, 0.6],\n",
    "[0, 0, 0.5, 0.5]])\n",
    "# observation probability matrix\n",
    "B = np.array([\n",
    "    [0.5, 0.5],\n",
    "    [0.6, 0.4],\n",
    "    [0.2, 0.8],\n",
    "    [0.3, 0.7]])\n",
    "# number of state\n",
    "N = 4\n",
    "# number of observation\n",
    "M = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three basic problem in HMM: probability estimation, learning problem and prediction problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation algorithm in HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability estimation problem in HMM is calculating $P(O|\\lambda)$, which is the probability of observation sequence $O$ appearing in the model $\\lambda$. And the probability estimation method of HMM is forward-backward algorithm. \n",
    "\n",
    "HMM define the forward probability as follow: the probability of observation sequence $o_{1},o_{2},\\cdots,o_{t}$ that are in the state of $q_{i}$ at time $t$ under the given model $\\lambda$\n",
    "$$\n",
    "\\alpha _{t}(i)=P(o_{1},o_{2},\\cdots,o_{t},i_{t}=q_{i}|\\lambda)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the definition above, the forward probability is a joint probability, and forward probability $\\alpha _{t}(i)$ and observation sequence probability $P(O|\\lambda)$ can be calculated recursively.With the input of HMM model $\\lambda$ and observation sequence $O$, output of observation sequence probability $P(O|\\lambda)$, the forward algorithm is expressed as below:\n",
    "\n",
    "• Value initialization: $\\alpha _{1}(i)=\\pi_{i}b_{i}(o_{1}), \\enspace i=1,2,\\cdots,N$\n",
    "\n",
    "• Recursion: $\\alpha_{i+1}(i)=\\left[\\sum_{j=1}^{N} \\alpha_{t}(j) a_{j i}\\right] b_{i}\\left(o_{t+1}\\right), \\quad i=1,2, \\ldots, N$ for $t=1,2,\\cdots,T-1$\n",
    "\n",
    "• Termination: $P(O|\\lambda)=\\sum^{N}_{i=1} \\alpha_ {T}(i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific derivation process of the forward probability algorithm is given below. According to the definition of forward probability, the initial value can be deduced as:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\alpha_{1}(i)&=P(o_{1},i_{1}=q_{i}|\\lambda) \\\\\n",
    "&=P(i_{1}=q_{i}|\\lambda)P(o_{1}|i_{1}=q_{i},\\lambda) \\\\\n",
    "&=\\pi_{i}b_{i}(o_{1})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$b_{i}(x)$ indicates the probability of generating state $q_{i}$ in observation, and assuming that observed data $o_{t}=v_{j}$ at time $t$:\n",
    "$$\n",
    "b_{i}(o_{t})=b_{i}(o_{t}=v_{j})=P(o_{t}=v_{j}|i_{t}=q_{i})=b_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the definition of forward probability:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\alpha _{T}(i)&=P(o_{1},o_{2},\\cdots,o_{T}, i_{T}=q_{i}|\\lambda) \\\\\n",
    "&=P(O, i_{T}=q_{i}|\\lambda)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the above formula, traversing the value of $i_{T}$ and summing them, the marginal probability of $O$ can be obtained:\n",
    "$$\n",
    "\\sum ^{N}_{i} \\alpha_{T}(i)=\\sum ^{N}_{i} P(O, i_{T}=q_{i}|\\lambda) = P(O|\\lambda)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $i_{t}=q_{i}$, there is:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\alpha_{t+1}(j)\n",
    "&=\\sum_{i=1}^{N} P\\left(o_{1}, o_{2}, \\ldots, o_{t+1}, i_{t}=q_{i}, i_{t+1}=q_{j} \\mid \\lambda\\right) \\\\\n",
    "&=\\sum_{i=1}^{N} P\\left(o_{t+1}, o_{1}, \\ldots, o_{t}, i_{t}=q_{i}, i_{t+1}=q_{j} \\mid \\lambda\\right) P\\left(o_{1}, o_{2}, \\ldots, o_{t}, i_{t}=q_{i}, i_{t+1}=q_{j} \\mid \\lambda\\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the derivation of the above formula, the first term can be simplified to:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&P\\left(o_{1}, o_{2}, \\ldots, o_{t+1}, i_{t}=q_{i}, i_{t+1}=q_{j} \\mid \\lambda\\right) \\\\\n",
    "=& P(o_{t+1}|i_{t+1}=q_{j}) \\\\\n",
    "=& b_{j}(o_{t+1})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the homogeneous Markov assumption the second term can be simplified as:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&P\\left(o_{t+1}, o_{1}, \\ldots, o_{t}, i_{t}=q_{i}, i_{t+1}=q_{j} \\mid \\lambda\\right) \\\\ \n",
    "&P\\left(o_{1}, o_{2}, \\ldots, o_{t}, i_{t}=q_{i}, i_{t+1}=q_{j} \\mid \\lambda\\right) \\\\\n",
    "=&P(i_{t+1}=q_{j}|i_{t}=q_{i})P(o_{1},\\cdots,o_{t}, i_{t}=q_{i}|\\lambda) \\\\\n",
    "=& a_{ij} \\alpha_{t}(i)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that $\\alpha_{t}(1), \\cdots, \\alpha_{t}(N) $ is known, and combining with the simplified results above, there is:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\alpha_{t+1}(j)&=P(o_{1},o_{2},\\cdots,o_{t+1},i_{t+1}=q_{j}|\\lambda) \\\\\n",
    "&= \\sum^{N}_{i=1}a_{ij}b_{j}(o_{t+1})\\alpha_{t}(i)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The backward probability algorithm can be derived in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward algorithm to calculate condition probability\n",
    "def prob_calc(O):\n",
    "    '''\n",
    "    input：O(observation sequence)\n",
    "    output：alpha.sum()(condition probability)\n",
    "    '''\n",
    "    # initial value\n",
    "    alpha = pi * B[:, O[0]]\n",
    "    # recursion\n",
    "    for o in O[1:]:\n",
    "        alpha_next = np.empty(4)\n",
    "        for j in range(4):\n",
    "            alpha_next[j] = np.sum(A[:,j] * alpha * B[j,o])\n",
    "        alpha = alpha_next\n",
    "    return alpha.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning algorithm in HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning problem in HMM is that, how to estimate the parameters in HMM model $\\lambda=(A,B, \\pi)$ to maximize the observation sequence probability $P(O|\\lambda)$ when the observation sequence $O=(o_{1}, o_{2}, \\cdots, o_{T})$ is known.\n",
    "\n",
    "If both observation sequence and corresponding state sequence are included in the training data, MLE can be used directly to estimate the model parameters. But in most cases, only observation sequence is in the training data. In this situation, the observation sequence is the observed data $O$ and the state sequence is the unobservable hidden data $I$, so the HMM model is actually a probability model with hidden variables.\n",
    "$$\n",
    "P(O|\\lambda)=\\sum _{I}P(O|I, \\lambda)P(I|\\lambda)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic models with hidden variables can be iteratively solved by the EM algorithm. Applying EM algorithm to solve HMM model parameters is also called the Baum-Welch algorithm. The process of solving HMM model parameters based on the Baum-Welch algorithm is as follows:\n",
    "\n",
    "(1) Determining the log-likelihood function for complete data: set the observed data as $O=(o_{1},o_{2},\\cdots,o_{T})$, hidden data as $I=(i_{1},i_{2},\\cdots,i_{T})$, complete data as $(O,I)=(o_{1},o_{2},\\cdots,o_{T},i_{1},i_{2},\\cdots,i_{T})$, and log-likelihood function for complete data as $\\log P(O,I|\\lambda)$\n",
    "\n",
    "(2) E step in EM algorithm: solve Q function $Q(\\lambda, \\bar{\\lambda})$, $\\bar{\\lambda}$ is the current estimation for HMM parameters, ${\\lambda}$ is to maximize HMM parameters\n",
    "$$\n",
    "Q(\\lambda, \\bar{\\lambda}) = \\sum_{I} \\log P(O,I|\\lambda)P(O,I|\\bar{\\lambda})  \\\\\n",
    "P(O, I \\mid \\lambda)=\\pi_{i_{1}} b_{i_{1}}\\left(o_{1}\\right) a_{i_{1} i_{2}} b_{i_{2}}\\left(o_{2}\\right) \\ldots a_{i_{T-1} i_{T}} b_{i_{T}}\\left(o_{T}\\right)\n",
    "$$\n",
    "\n",
    "(3) M step in EM algorithm: maximize Q function $Q(\\lambda, \\bar{\\lambda})$ to obtain model parameters $A, B, \\pi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction algorithm in HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction problem of HMM is finding the most likely corresponding state sequence $I=(i_{1},i_{2},\\cdots,i_{T})$ (with largest condition probability $P(I|O)$) when the model $\\lambda=(A,B,\\pi)$ and observation sequence $O=(o_{1},o_{2},\\cdots,o_{T})$ are known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction algorithm of HMM is a problem of solving the optimal path that it can be solved by Viterbi algorithm. The HMM optimal path solution process based on Viterbi algorithm is as follows:\n",
    "\n",
    "(1) Initialization: \n",
    "$$\n",
    "\\delta_{1}(i)=\\pi_{i} b_{i}\\left(o_{1}\\right), \\enspace \\Psi_{1}(i)=0, \\enspace i=1,2, \\ldots, N\n",
    "$$\n",
    "\n",
    "(2) Recursion: for $t=2,3,\\cdots,T$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\delta_{t}(i)=\\max _{1<=j<=N}\\left[\\delta_{t-1}(j) a_{j i}\\right] b_{i}\\left(o_{t}\\right) \\\\\n",
    "&\\Psi_{t}(i)=\\arg \\max _{1<=j<=N}\\left[\\delta_{t-1}(j) a_{j i}\\right], \\quad i=1,2, \\ldots, N\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "(3) Termination: \n",
    "$$\n",
    "P^{*}=\\max _{1<=j<=N} \\delta_{T}(i) i_{T}^{*}=\\arg \\max _{1<=j<=N}\\left[\\delta_{T}(i)\\right]\n",
    "$$\n",
    "\n",
    "(4) Optimal path backtracking: for $t=T-1, T-2, \\cdots, 1$\n",
    "$$\n",
    "i^{*}_{t}= \\Psi_{t+1}(i^{*}_{t+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decode(O):\n",
    "    '''\n",
    "    input：O(observation sequence)\n",
    "    output：path(optimal hidden state path)\n",
    "    '''    \n",
    "    # sequence length and initial observation\n",
    "    T, o = len(O), O[0]\n",
    "    # initialize delta \n",
    "    delta = pi * B[:, o]\n",
    "    # initialize varphi\n",
    "    varphi = np.zeros((T, 4), dtype=int)\n",
    "    path = [0] * T\n",
    "    # recursion\n",
    "    for i in range(1, T):\n",
    "        delta = delta.reshape(-1, 1)     \n",
    "        tmp = delta * A\n",
    "        varphi[i, :] = np.argmax(tmp, axis=0)\n",
    "        delta = np.max(tmp, axis=0) * B[:, O[i]]\n",
    "    # termination\n",
    "    path[-1] = np.argmax(delta)\n",
    "    # optimal path backtracking\n",
    "    for i in range(T-1, 0, -1):\n",
    "        path[i-1] = varphi[i, path[i]]\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 1]\n",
      "0.06247567374999999\n",
      "[1, 2, 3, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "hmm = generate(N, M, pi, A, B, 5)\n",
    "print(hmm)\n",
    "print(prob_calc(hmm))\n",
    "print(viterbi_decode(hmm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
