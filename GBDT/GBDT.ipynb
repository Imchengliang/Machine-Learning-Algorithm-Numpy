{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBDT(Gradient Boosting Decision Tree) is the core model of ensemble learning, which is also one kind of decision tree model algorithm. GBDT consists of decision tree, boosting model, and gradient descent.\n",
    "\n",
    "The basic principle of decision tree is the process of continuously selecting features to build a tree model according to the information divergence (or other criterion). Boosting is an ensemble learning mode, which is a process of linearly combining multiple single decision trees (weak learners) to form a strong learner. Boosting uses a single model as a weak classifier, and CART is the weak classifier in GBDT. And after integrating gradient descent to optimize the boosting tree model, there is a gradient boosting tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A boosting tree model can be described as follow:\n",
    "$$\n",
    "f_{M}(x)=\\sum_{m=1}^{M} T\\left(x ; \\Theta_{m}\\right)\n",
    "$$\n",
    "\n",
    "Under the given model, the $m$-th step is:\n",
    "$$\n",
    "f_{m}(x)=f_{m-1}(x) T\\left(x ; \\Theta_{m}\\right)\n",
    "$$\n",
    "\n",
    "Then we optimize the parameters of the next tree by the following objective function:\n",
    "$$\n",
    "\\hat{\\Theta}_{m}=\\underset{\\Theta_{m}}{\\arg \\min } \\sum_{i=1}^{N} L\\left(y_{i}, f_{m-1}\\left(x_{i}\\right)+T\\left(x_{i} ; \\Theta_{m}\\right)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the boosting tree of regression problem as example, a regression tree can be expressed as follow:\n",
    "$$\n",
    "T\\left(x ; \\Theta \\right) = \\sum ^{J}_{j=1}c_{j}I(x \\in R_{j})\n",
    "$$\n",
    "\n",
    "The $0$-th, $m$-th step and final model are:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&f_{0}(x)=0 \\\\\n",
    "&f_{m}(x)=f_{m-1}(x)+T\\left(x ; \\Theta_{m}\\right), m=1,2, \\cdots, M \\\\\n",
    "&f_{M}(x)=\\sum_{m=1}^{M} T\\left(x ; \\Theta_{m}\\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the given $m-1$-th step model to solve:\n",
    "$$\n",
    "\\hat{\\Theta}_{m}=\\underset{\\Theta_{m}}{\\arg \\min } \\sum_{i=1}^{N} L\\left(y_{i}, f_{m-1}\\left(x_{i}\\right)+T\\left(x_{i} ; \\Theta_{m}\\right)\\right)\n",
    "$$\n",
    "\n",
    "When the loss function is squared loss:\n",
    "$$\n",
    "L(y, f(x))=(y-f(x))^{2}\n",
    "$$\n",
    "\n",
    "The corresponding loss can be expressed as:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&L(y, f_{m-1}\\left(x_{i}\\right)+T\\left(x ; \\Theta_{m}\\right)) \\\\\n",
    "=&[y-f_{m-1}\\left(x_{i}\\right)-T\\left(x ; \\Theta_{m}\\right)]^{2} \\\\\n",
    "=&[r-T(x: \\Theta_{m})]^{2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Then $\\enspace r=y-f_{m-1}(x) \\enspace$ is obtained, which indicates each iteration of boosting tree model is fitting a residual function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in practice, not every loss function is as easy to optimize as squared loss, so an approximate gradient descent method is proposed to use the value of the negative gradient of the loss function in the current model as an approximation of the residual in the regression boosting tree. which is:\n",
    "$$\n",
    "r_{im}=-\\left[\\frac{\\partial L\\left(y_{i}, f\\left(x_{i}\\right)\\right)}{\\partial f\\left(x_{i}\\right)}\\right]_{f(x)=f_{m-1}(x)}\n",
    "$$\n",
    "\n",
    "Therefore, combining boosting tree and gradient boosting, the general process of the GBDT model algorithm can be summarized as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Initialize the weak learner:\n",
    "$$\n",
    "f_{0}(x) = \\arg \\min_{c} \\sum^{N}_{i=1}L(y_{i}, c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) For $m = 1,2, \\cdots , M$:\n",
    "\n",
    "Calculate negative gradient (residual) for every sample $i= 1,2, \\cdots , N$:\n",
    "$$\n",
    "r_{im}=-\\left[\\frac{\\partial L\\left(y_{i}, f\\left(x_{i}\\right)\\right)}{\\partial f\\left(x_{i}\\right)}\\right]_{f(x)=f_{m-1}(x)}\n",
    "$$\n",
    "\n",
    "The residual obtained in the previous step is used as the new real value of the sample, and the data $(x_{i}, r_{im}), i= 1,2, \\cdots , N$ are used as the training data of the next tree to obtain a new regression tree $f_{m}(x)$ whose corresponding leaf node area are $R_{jm}, j= 1,2, \\cdots , J$. And $J$ is the number of leaf node in the regression tree.\n",
    "\n",
    "Calculate the best fitted value for leaf node area $j= 1,2, \\cdots , J$\n",
    "$$\n",
    "r_{j m}=\\underbrace{\\arg \\min }_{r} \\sum_{x_{i} \\in R_{j m}} L\\left(y_{i}, f_{m-1}\\left(x_{i}\\right) r \\right)\n",
    "$$\n",
    "\n",
    "Update the string learner:\n",
    "$$\n",
    "f_{m}(x) = f_{m-1}(x) \\sum^{J}_{j=1} r_{jm}I(x \\in R_{jm})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Obtain the final learner:\n",
    "$$\n",
    "f(x)=f_{M}(x) = f_{0}(x) \\sum^{M}_{m=1} \\sum^{J}_{j=1} r_{jm}I(x \\in R_{jm})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from CART import TreeNode, BinaryDecisionTree, ClassificationTree, RegressionTree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from CART import feature_split, calculate_gini, data_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBDT(object):\n",
    "    def __init__(self, n_estimators, learning_rate, min_samples_split, min_gini_impurity, max_depth, regression):\n",
    "        # number of tree\n",
    "        self.n_estimators = n_estimators\n",
    "        # step size for weight update\n",
    "        self.learning_rate = learning_rate\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_gini_impurity = min_gini_impurity\n",
    "        self.max_depth = max_depth\n",
    "        # default is regression tree\n",
    "        self.regression = regression\n",
    "        # square loss as loss function\n",
    "        self.loss = SquareLoss()\n",
    "        # use other loss function for classification tree\n",
    "        if not self.regression:\n",
    "            self.loss = SotfMaxLoss()\n",
    "        # combine multiple trees to form a strong learner\n",
    "        self.estimators = []\n",
    "        for i in range(self.n_estimators):\n",
    "            self.estimators.append(RegressionTree(min_samples_split=self.min_samples_split,\n",
    "                                                min_gini_impurity=self.min_gini_impurity,\n",
    "                                                max_depth=self.max_depth))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # forward step model initialize the first tree\n",
    "        self.estimators[0].fit(X, y)\n",
    "        # prediction for the first tree\n",
    "        y_pred = self.estimators[0].predict(X)\n",
    "        # forward step iterative training\n",
    "        for i in range(1, self.n_estimators):\n",
    "            gradient = self.loss.gradient(y, y_pred)\n",
    "            self.estimators[i].fit(X, gradient)\n",
    "            y_pred -= np.multiply(self.learning_rate, self.estimators[i].predict(X))\n",
    "\n",
    "    def predict(self, X):\n",
    "        # prediction for regression tree\n",
    "        y_pred = self.estimators[0].predict(X)\n",
    "        for i in range(1, self.n_estimators):\n",
    "            y_pred -= np.multiply(self.learning_rate, self.estimators[i].predict(X))\n",
    "        # prediction for classification tree\n",
    "        if not self.regression:\n",
    "            # transform the predicted value into probability\n",
    "            y_pred = np.exp(y_pred) / np.expand_dims(np.sum(np.exp(y_pred), axis=1), axis=1)\n",
    "            # transform into label\n",
    "            y_pred = np.argmax(y_pred, axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression tree\n",
    "class GBDTRegressor(GBDT):\n",
    "    def __init__(self, n_estimators=300, learning_rate=0.1, min_samples_split=2,\n",
    "                min_var_reduction=1e-6, max_depth=3):\n",
    "        super(GBDTRegressor, self).__init__(n_estimators=n_estimators,\n",
    "                                            learning_rate=learning_rate,\n",
    "                                            min_samples_split=min_samples_split,\n",
    "                                            min_gini_impurity=min_var_reduction,\n",
    "                                            max_depth=max_depth,\n",
    "                                            regression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification tree\n",
    "class GBDTClassifier(GBDT):\n",
    "    def __init__(self, n_estimators=200, learning_rate=.5, min_samples_split=2,\n",
    "                min_info_gain=1e-6, max_depth=2):\n",
    "            super(GBDTClassifier, self).__init__(n_estimators=n_estimators,\n",
    "                                                learning_rate=learning_rate,\n",
    "                                                min_samples_split=min_samples_split,\n",
    "                                                min_gini_impurity=min_info_gain,\n",
    "                                                max_depth=max_depth,\n",
    "                                                regression=False)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        super(GBDTClassifier, self).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquareLoss():\n",
    "    def loss(self, y, y_pred):\n",
    "        return 0.5 * np.power((y - y_pred), 2)\n",
    "\n",
    "    def gradient(self, y, y_pred):\n",
    "        return -(y - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1108)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py:1319\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1319\u001b[0m     h\u001b[39m.\u001b[39;49mrequest(req\u001b[39m.\u001b[39;49mget_method(), req\u001b[39m.\u001b[39;49mselector, req\u001b[39m.\u001b[39;49mdata, headers,\n\u001b[1;32m   1320\u001b[0m               encode_chunked\u001b[39m=\u001b[39;49mreq\u001b[39m.\u001b[39;49mhas_header(\u001b[39m'\u001b[39;49m\u001b[39mTransfer-encoding\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m   1321\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/client.py:1230\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1229\u001b[0m \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1230\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/client.py:1276\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1276\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/client.py:1225\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1224\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1225\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/client.py:1004\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1004\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1006\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1007\u001b[0m \n\u001b[1;32m   1008\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/client.py:944\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 944\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    945\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/client.py:1399\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1397\u001b[0m     server_hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[0;32m-> 1399\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context\u001b[39m.\u001b[39;49mwrap_socket(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msock,\n\u001b[1;32m   1400\u001b[0m                                       server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/ssl.py:500\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    496\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    498\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[1;32m    501\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[1;32m    502\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[1;32m    503\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[1;32m    504\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[1;32m    505\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[1;32m    506\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    507\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[1;32m    508\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/ssl.py:1040\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1040\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   1041\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/ssl.py:1309\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 1309\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   1310\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1108)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/imchengliang/Downloads/Code/ML/GBDT/GBDT.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/imchengliang/Downloads/Code/ML/GBDT/GBDT.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#from sklearn import datasets\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/imchengliang/Downloads/Code/ML/GBDT/GBDT.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m fetch_california_housing\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/imchengliang/Downloads/Code/ML/GBDT/GBDT.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X, y \u001b[39m=\u001b[39m fetch_california_housing(return_X_y\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/imchengliang/Downloads/Code/ML/GBDT/GBDT.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#boston = datasets.load_boston()\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/imchengliang/Downloads/Code/ML/GBDT/GBDT.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#X, y = data_shuffle(boston.data, boston.target, seed=13)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/imchengliang/Downloads/Code/ML/GBDT/GBDT.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/datasets/_california_housing.py:138\u001b[0m, in \u001b[0;36mfetch_california_housing\u001b[0;34m(data_home, download_if_missing, return_X_y, as_frame)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mData not found and `download_if_missing` is False\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    135\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mDownloading Cal. housing from \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(ARCHIVE\u001b[39m.\u001b[39murl, data_home)\n\u001b[1;32m    136\u001b[0m )\n\u001b[0;32m--> 138\u001b[0m archive_path \u001b[39m=\u001b[39m _fetch_remote(ARCHIVE, dirname\u001b[39m=\u001b[39;49mdata_home)\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m tarfile\u001b[39m.\u001b[39mopen(mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mr:gz\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39marchive_path) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    141\u001b[0m     cal_housing \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mloadtxt(\n\u001b[1;32m    142\u001b[0m         f\u001b[39m.\u001b[39mextractfile(\u001b[39m\"\u001b[39m\u001b[39mCaliforniaHousing/cal_housing.data\u001b[39m\u001b[39m\"\u001b[39m), delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/datasets/_base.py:1511\u001b[0m, in \u001b[0;36m_fetch_remote\u001b[0;34m(remote, dirname)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[39m\"\"\"Helper function to download a remote dataset into path\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m \n\u001b[1;32m   1491\u001b[0m \u001b[39mFetch a dataset pointed by remote's url, save into path using remote's\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[39m    Full path of the created file.\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m file_path \u001b[39m=\u001b[39m remote\u001b[39m.\u001b[39mfilename \u001b[39mif\u001b[39;00m dirname \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m join(dirname, remote\u001b[39m.\u001b[39mfilename)\n\u001b[0;32m-> 1511\u001b[0m urlretrieve(remote\u001b[39m.\u001b[39;49murl, file_path)\n\u001b[1;32m   1512\u001b[0m checksum \u001b[39m=\u001b[39m _sha256(file_path)\n\u001b[1;32m   1513\u001b[0m \u001b[39mif\u001b[39;00m remote\u001b[39m.\u001b[39mchecksum \u001b[39m!=\u001b[39m checksum:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py:247\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    245\u001b[0m url_type, path \u001b[39m=\u001b[39m _splittype(url)\n\u001b[0;32m--> 247\u001b[0m \u001b[39mwith\u001b[39;00m contextlib\u001b[39m.\u001b[39mclosing(urlopen(url, data)) \u001b[39mas\u001b[39;00m fp:\n\u001b[1;32m    248\u001b[0m     headers \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39minfo()\n\u001b[1;32m    250\u001b[0m     \u001b[39m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[39m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 222\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    522\u001b[0m     req \u001b[39m=\u001b[39m meth(req)\n\u001b[1;32m    524\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[0;32m--> 525\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(req, data)\n\u001b[1;32m    527\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n\u001b[1;32m    528\u001b[0m meth_name \u001b[39m=\u001b[39m protocol\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_response\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py:542\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    541\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[0;32m--> 542\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_open, protocol, protocol \u001b[39m+\u001b[39;49m\n\u001b[1;32m    543\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39m_open\u001b[39;49m\u001b[39m'\u001b[39;49m, req)\n\u001b[1;32m    544\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m    545\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    501\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 502\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    503\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py:1362\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[0;32m-> 1362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_open(http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mHTTPSConnection, req,\n\u001b[1;32m   1363\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context, check_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_hostname)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py:1322\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         h\u001b[39m.\u001b[39mrequest(req\u001b[39m.\u001b[39mget_method(), req\u001b[39m.\u001b[39mselector, req\u001b[39m.\u001b[39mdata, headers,\n\u001b[1;32m   1320\u001b[0m                   encode_chunked\u001b[39m=\u001b[39mreq\u001b[39m.\u001b[39mhas_header(\u001b[39m'\u001b[39m\u001b[39mTransfer-encoding\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m   1321\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m         \u001b[39mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1323\u001b[0m     r \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m   1324\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1108)>"
     ]
    }
   ],
   "source": [
    "#from sklearn import datasets\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "#boston = datasets.load_boston()\n",
    "#X, y = data_shuffle(boston.data, boston.target, seed=13)\n",
    "X = X.astype(np.float32)\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "model = GBDTRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "# Color map\n",
    "cmap = plt.get_cmap('viridis')\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print (\"Mean Squared Error of NumPy GBRT:\", mse)\n",
    "\n",
    "# Plot the results\n",
    "m1 = plt.scatter(range(X_test.shape[0]), y_test, color=cmap(0.5), s=10)\n",
    "m2 = plt.scatter(range(X_test.shape[0]), y_pred, color='black', s=10)\n",
    "plt.suptitle(\"Regression Tree\")\n",
    "plt.title(\"MSE: %.2f\" % mse, fontsize=10)\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('house price')\n",
    "plt.legend((m1, m2), (\"Test data\", \"Prediction\"), loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
